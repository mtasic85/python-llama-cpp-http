[tool.poetry]
name = "llama_cpp_http"
version = "0.1.0"
description = "Python llama.cpp HTTP Server and LangChain LLM Client"
authors = ["Marko Tasic <mtasic85@gmail.com>"]
license = "MIT"
readme = "README.md"
packages = [{include = "llama_cpp_http"}]

[tool.poetry.dependencies]
python = "^3.10"
pyopencl = "^2023.1.2"
aiohttp = {extras = ["speedups"], version = "^3.8.5"}
async-timeout = "^4.0.3"
websockets = "^11.0.3"
requests = "^2.31.0"
langchain = "^0.0.268"
pony = "^0.7.16"


[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
